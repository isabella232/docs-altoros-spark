---
title: Installing and Configuring Altoros Spark for PCF
owner: Partners
---

This topic describes how to install and configure Altoros Spark for PCF.

##<a id='install'></a> Install and Configure Altoros Spark for PCF

1. Download the product file from [Pivotal Network](http://network.pivotal.io).

1. Navigate to the Ops Manager Installation Dashboard and click **Import a Product** to upload the product file.

1. Click **Add** next to the uploaded Altoros Spark for PCF tile
   in the Ops Manager **Available Products** view to add it to your staging area.

1. Click the newly added **Altoros Spark for PCF** tile.

1. Click **Altoros Spark for PCF**.
	![Ops Man Config](images/config-v0.6.0.png)

1. For **Apache Spark VM Type**, use the dropdown menu to select the type of VM to use for each Apache Spark node. The dropdown menu is automatically populated with the list of VMs configured for your cloud environment.

1. For **Apache Spark Disk Type**, use the dropdown menu to select the type of disc to use for each Apache Spark node.

1. For **Apache Spark availability zone(s)**, select the checkboxes that correspond with the availability zones where you plan to deploy Apache Spark. The availability zones must have an associated service network.

1. Click **Save**.

1. Return to the Ops Manager Installation Dashboard and click **Apply changes** to install Altoros Spark for PCF tile.

1. After the installation finishes, see [Creating and Binding Apache Spark Service Instances](using.html) for how to create and bind Apache Spark service instances.
